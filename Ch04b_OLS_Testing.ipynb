{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS, Testing\n",
    "\n",
    "This notebook estimates a linear regression and tests various hypotheses using standard errors assuming *(a)* iid residuals (Gauss-Markov assumptions); *(b)* heteroskedasticity (White); *(c)* autocorrelation and heteroskedasticity (Newey-West).\n",
    "\n",
    "You may also consider the [HypothesisTests.jl](https://github.com/JuliaStats/HypothesisTests.jl) package (not used here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages and Extra Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Printf, DelimitedFiles, Statistics, LinearAlgebra, Distributions\n",
    "\n",
    "include(\"jlFiles/printmat.jl\")\n",
    "include(\"jlFiles/Ols.jl\");         #functions for OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:    (388,)\n"
     ]
    }
   ],
   "source": [
    "x = readdlm(\"Data/FFmFactorsPs.csv\",',',skipstart=1)\n",
    "\n",
    "                #yearmonth, market, small minus big, high minus low\n",
    "(ym,Rme,RSMB,RHML) = (x[:,1],x[:,2]/100,x[:,3]/100,x[:,4]/100)\n",
    "x = nothing\n",
    "\n",
    "printlnPs(\"Sample size:\",size(Rme))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS under the Gauss-Markov Assumptions\n",
    "\n",
    "(assuming iid residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mOLS Results (assuming iid residuals):\u001b[22m\u001b[39m\n",
      "\n",
      "            b   std_iid\n",
      "c       0.007     0.002\n",
      "SMB     0.217     0.073\n",
      "HML    -0.429     0.074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = Rme\n",
    "T = size(Y,1)\n",
    "X = [ones(T) RSMB RHML]\n",
    "\n",
    "(b,u,_,V,R²) = OlsGMFn(Y,X)\n",
    "std_iid = sqrt.(diag(V))\n",
    "\n",
    "printblue(\"OLS Results (assuming iid residuals):\\n\")\n",
    "xNames = [\"c\",\"SMB\",\"HML\"]\n",
    "printmat(b,std_iid;colNames=[\"b\",\"std_iid\"],rowNames=xNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a Joint Hypothesis\n",
    "\n",
    "Since the estimator $\\hat{\\beta}_{_{k\\times1}}$ satisfies\n",
    "\n",
    "$\n",
    "\\hat{\\beta}-\\beta_{0} \\sim N(0,V_{k\\times k})  ,\n",
    "$\n",
    "\n",
    "we can easily apply various tests. Consider a joint linear hypothesis of the\n",
    "form\n",
    "\n",
    "$\n",
    "H_0: R\\beta=q,\n",
    "$\n",
    "\n",
    "where $R$ is a $J \\times k$ matrix and $q$ is a $J$-vector. To test this, use\n",
    "\n",
    "$\n",
    "(R\\beta-q)^{\\prime}(RVR^{\\prime}) ^{-1}(R\\beta\n",
    "-q)\\overset{d}{\\rightarrow}\\chi_{J}^{2}.\n",
    "$\n",
    "\n",
    "How we estimate $V$ depends on whether there is heteroskedasticity and/or autocorrelation (discussed below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTesting Rb = a:\u001b[22m\u001b[39m\n",
      "test statistic        60.010\n",
      "10% critical value     4.605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R = [0 1 0;               #testing if b₂=0 and b₃=0\n",
    "     0 0 1]\n",
    "q = [0;0]\n",
    "test_stat = (R*b-q)'inv(R*V*R')*(R*b-q)    #R*V*R' is 2x2\n",
    "\n",
    "printblue(\"Testing Rb = a:\")\n",
    "printmat([test_stat,quantile(Chisq(2),0.9)];rowNames=[\"test statistic\",\"10% critical value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of OLS Estimates without the Gauss-Markov Assumptions\n",
    "\n",
    "\n",
    "The distribution of the OLS estimates is (typically)\n",
    "\n",
    "$\n",
    "(\\hat{\\beta}-\\beta_{0})\\overset{d}{\\rightarrow}N(0,V)\n",
    "\\: \\text{ where } \\: V=S_{xx}^{-1} S S_{xx}^{-1}.\n",
    "$\n",
    "\n",
    "and where $S_{xx} = \\sum\\nolimits_{t=1}^{T}x_{t}x_{t}^{\\prime}$ \n",
    "and $S$ is the covariance matrix of $\\sum_{t=1}^{T}u_{t}x_{t}$.\n",
    "\n",
    "\n",
    "*When* the Gauss-Markov assumptions hold, then $S$ can be simplified to $S_{xx}\\sigma^2$, where $\\sigma^2$ is the variance of $u_t$, so $V=S_{xx}^{-1}\\sigma^2$.\n",
    "\n",
    "In contrast, with heteroskedasticity and/or autocorrelation, $S$ must be estimated differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White's Covariance Matrix\n",
    "\n",
    "If $u_{t}x_{t}$ is not autocorrelated, then $S$ simplifies to $\\sum_{t=1}^{T} x_tx_t^{\\prime}\\sigma_t^2$. White's method replaces $\\sigma_t^2$ by $\\hat{u}_{t}^{2}$. This estimate is robust to heteroskedasticity (in particular, time variation in $\\sigma_t^2$ that is related to $x_t$).\n",
    "\n",
    "## A Remark on the Code\n",
    "$S_{xx}$ can be calculated as `Sxx = X'X` and $S$ as `S = (X.*u)'*(X.*u)`.\n",
    "\n",
    "Clearly, these calculations can also be done in a loop like\n",
    "```\n",
    "for t = 1:T\n",
    "   Sxx = Sxx + X[t,:]*X[t,:]' \n",
    "   S   = S   + X[t,:]*X[t,:]'*u[t]^2\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mCoefficients and standard errors (from different methods):\u001b[22m\u001b[39m\n",
      "\n",
      "              b     std_iid   std_White\n",
      "c         0.007       0.002       0.002\n",
      "SMB       0.217       0.073       0.113\n",
      "HML      -0.429       0.074       0.097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sxx = X'X\n",
    "\n",
    "S     = (X.*u)'*(X.*u)                #S according to White's method\n",
    "V     = inv(Sxx)'S*inv(Sxx)           #Cov(b), White\n",
    "std_W = sqrt.(diag(V))\n",
    "\n",
    "printblue(\"Coefficients and standard errors (from different methods):\\n\")\n",
    "xx = [b std_iid std_W]\n",
    "printmat(xx;colNames=[\"b\",\"std_iid\",\"std_White\"],rowNames=xNames,width=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newey-West's Covariance Matrix\n",
    "\n",
    "Let $g_t=u_{t}x_{t}$ be a $k$-vector of data.\n",
    "\n",
    "To calculate the Newey-West covariance matrix, we first need\n",
    "\n",
    "$ \n",
    "\\Lambda_{s} = \\sum_{t=s+1}^{T} (g_{t}-\\bar{g})(g_{t-s}-\\bar{g})^{\\prime},\n",
    "$\n",
    "\n",
    "which is proportional to the $s$th autocovariance matrices.\n",
    "\n",
    "Then we form a linear\n",
    "combination (with tent-shaped weights) of those autocovariance matrices (from\n",
    "lag $-m$ to $m$) as in\n",
    "\n",
    "$\n",
    "S = \\mathrm{Cov}(\\sum_t g_t)  = \n",
    "\\Lambda_{0} + \\sum_{s=1}^{m}( 1-\\frac{s}{m+1})  \n",
    "(\\Lambda_{s}+\\Lambda_{s}^{\\prime}).\n",
    "$\n",
    "\n",
    "With $m=0$ this is the same as White's method.\n",
    "\n",
    "If we divide $S$ by $T$, then we get an estimate of $\\mathrm{Cov}(\\sqrt{T} \\bar{g})$, and if we instead divide by $T^2$ then we get an estimate of $\\mathrm{Cov}(\\bar{g})$.\n",
    "\n",
    "The `CovNWFn()` function (below and also in `CovNWFn.jl`) implements this. \n",
    "\n",
    "## A Remark on the Code\n",
    "$\\Lambda_{s}$  can be calculated by `g[s+1:T,:]'g[1:T-s,:]` where `g` is already demeaned. (A loop would also work.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CovNWFn"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    CovNWFn(g0,m=0,DivideByT=0)\n",
    "\n",
    "Calculates covariance matrix of sample sum (DivideByT=0), scaled average (DivideByT=1) or\n",
    "average (DivideByT=2).\n",
    "\n",
    "\n",
    "# Input\n",
    "- `g0::Matrix`:      Txq Matrix of q moment conditions\n",
    "- `m::Int`:          number of lags to use\n",
    "- `DivideByT::Int`:  divide the result by T^DivideByT\n",
    "\n",
    "# Output\n",
    "- `S::Matrix`: qxq covariance matrix\n",
    "\n",
    "# Remark\n",
    "- `DivideByT=0`: Var(x_1+x_2+...X_T)\n",
    "- `DivideByT=1`: Var((x_1+x_2+...X_T)/sqrt(T))\n",
    "- `DivideByT=2`: Var((x_1+x_2+...X_T)/T)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "function CovNWFn(g0,m=0,DivideByT=0)\n",
    "\n",
    "    T = size(g0,1)                    #g0 is Txq\n",
    "    m = min(m,T-1)                    #number of lags\n",
    "\n",
    "    g = g0 .- mean(g0,dims=1)         #normalizing to zero means\n",
    "\n",
    "    S = g'g                           #(qxT)*(Txq)\n",
    "    for s = 1:m\n",
    "        Λ_s = g[s+1:T,:]'g[1:T-s,:]   #same as Sum[g_t*g_{t-s}',t=s+1,T]\n",
    "        S   = S  +  (1 - s/(m+1))*(Λ_s + Λ_s')\n",
    "    end\n",
    "\n",
    "    (DivideByT > 0) && (S = S/T^DivideByT)\n",
    "\n",
    "    return S\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mCoefficients and standard errors (from different methods):\u001b[22m\u001b[39m\n",
      "\n",
      "                  b         std_iid       std_White          std_NW   std_NW 0 lags\n",
      "c             0.007           0.002           0.002           0.002           0.002\n",
      "SMB           0.217           0.073           0.113           0.129           0.113\n",
      "HML          -0.429           0.074           0.097           0.118           0.097\n",
      "\n",
      "\u001b[31m\u001b[1mRemark: NW with 0 lags should be the same as White's method\u001b[22m\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "S      = CovNWFn(X.*u,2)         #S acccording to Newey-West, 2 lags\n",
    "V      = inv(Sxx)'S*inv(Sxx)     #Cov(b), Newey-West\n",
    "std_NW = sqrt.(diag(V))\n",
    "\n",
    "S       = CovNWFn(X.*u,0)         #S acccording to Newey-West, 0 lags\n",
    "V       = inv(Sxx)'S*inv(Sxx)\n",
    "std_NW0 = sqrt.(diag(V))\n",
    "\n",
    "printblue(\"Coefficients and standard errors (from different methods):\\n\")\n",
    "xx = [b std_iid std_W std_NW std_NW0]\n",
    "printmat(xx,colNames=[\"b\",\"std_iid\",\"std_White\",\"std_NW\",\"std_NW 0 lags\"],rowNames=xNames,width=16)\n",
    "\n",
    "printred(\"Remark: NW with 0 lags should be the same as White's method\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
