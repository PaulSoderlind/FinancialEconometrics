{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel Regressions\n",
    "\n",
    "This notebook illustrates several panel data models and estimation methods (pooled OLS, fixed effects, the \"between\" estimator, first differences, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages and Extra Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Printf, DelimitedFiles, Statistics, LinearAlgebra\n",
    "\n",
    "include(\"jlFiles/printmat.jl\")\n",
    "include(\"jlFiles/CovNWFn.jl\")\n",
    "include(\"jlFiles/Ols.jl\")\n",
    "include(\"jlFiles/lagFn.jl\")\n",
    "include(\"jlFiles/excise.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "### A Remark on the Code\n",
    "\n",
    "The data set contains many variables (one per column). It is convenient to store them as a named tuple where the names are taken directly from the header in the file. This allows us to later use, for instance, `X.lwage` to refer to the data on log wages. Since this is fully automatic, it also reduces the risk of referring to the wrong data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PutDataInNT"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    PutDataInNT(x,header)\n",
    "\n",
    "Creates a NamedTuple with, for instance, `X.a`, `X.b` and `X.c` where `x` is a matrix and `header = [\"a\" \"b\" \"c\"]`.\n",
    "\n",
    "\"\"\"\n",
    "function PutDataInNT(x,header)\n",
    "    namesB = tuple(Symbol.(header)...)                            #a tuple (:a,:b,:b)\n",
    "    X      = NamedTuple{namesB}([x[:,i] for i=1:size(x,2)])       #NamedTuple with X.a, X.b and X.c\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:id, :year, :lwage, :hours, :age, :educ, :collgrad, :msp, :nev_mar, :not_smsa, :c_city, :south, :black, :union, :exper, :exper2, :tenure, :tenure2)\n",
      "\n",
      "T=5 and N=716\n"
     ]
    }
   ],
   "source": [
    "(x,header) = readdlm(\"Data/nls_panelEd.txt\",header=true)    #classical data set from Hill et al (2008)\n",
    "\n",
    "X = PutDataInNT(x,header)                         #NamedTuple with X.id, X.lwage, etc\n",
    "println(keys(X))\n",
    "\n",
    "NT = size(x,1)\n",
    "c  = ones(NT)\n",
    "\n",
    "T = 5                 #number of time periods\n",
    "N = round(Int,NT/T)   #number of individuals\n",
    "\n",
    "id = X.id\n",
    "\n",
    "println(\"\\nT=$T and N=$N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Variables for the Regressions\n",
    "\n",
    "The next cell creates a matrix $yx$ which has the dependent variable as the first column and the regressors as the remaining columns.\n",
    "\n",
    "We then print the first few observations of (some of) the data. Notice the structure: the first 5 observations are for individual (`id`) 1 (period 1-5), the next 5 for individual 2.\n",
    "\n",
    "The subsequent cell makes a \"within transformation\" by creating \n",
    "\n",
    "$\n",
    "yx^*_{it} = yx_{it} - \\bar{yx}_{it}, \n",
    "$\n",
    "\n",
    "where $\\bar{yx}_{it}$ is a row vector with the averages of each column of $yx$ for individual $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mThe first few lines of (some of) the data:\u001b[22m\u001b[39m\n",
      "\n",
      "obs        id    lnwage         c exper/100\n",
      "1       1.000     1.808     1.000     0.077\n",
      "2       1.000     1.863     1.000     0.086\n",
      "3       1.000     1.789     1.000     0.102\n",
      "4       1.000     1.847     1.000     0.122\n",
      "5       1.000     1.856     1.000     0.136\n",
      "6       2.000     1.281     1.000     0.076\n",
      "7       2.000     1.516     1.000     0.084\n",
      "8       2.000     1.930     1.000     0.104\n",
      "9       2.000     1.919     1.000     0.120\n",
      "10      2.000     2.201     1.000     0.132\n",
      "11      3.000     1.815     1.000     0.114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xNames = [\"exper/100\",\"exper^2/100\",\"tenure/100\",\"tenure^2/100\",\"south\",\"union\"]\n",
    "yx     = [X.lwage c X.exper/100 X.exper2/100 X.tenure/100 X.tenure2/100 X.south X.union]\n",
    "K      = size(yx,2) - 1\n",
    "\n",
    "printblue(\"The first few lines of (some of) the data:\\n\")\n",
    "printmat(Any[id[1:11] yx[1:11,1:3]],colNames=[\"id\",\"lnwage\",\"c\",\"exper/100\"],rowNames=string.(1:11),cell00=\"obs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_uniq = unique(id)               #which id values are in data set\n",
    "N       = length(id_uniq)          #number of cross-sectional units\n",
    "\n",
    "yxStar = fill(NaN,size(yx))          #individual de-meaning\n",
    "yxbar  = fill(NaN,N,1+K) \n",
    "for i = 1:N                          #loop over individuals\n",
    "    #local vv_i                      #local/global is needed in script\n",
    "    vv_i          = id .== id_uniq[i]                #locate rows in yx which refer to individual i\n",
    "    yxbar[i,:]    = mean(yx[vv_i,:],dims=1)          #averages for individual i\n",
    "    yxStar[vv_i,:] = yx[vv_i,:] .- yxbar[i:i,:]      #i:i to keep it a row vector\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled OLS, FE, and Between Estimations\n",
    "\n",
    "'Pooled OLS' is just OLS on the original data `(y,x)`, 'fixed effects' (FE) is on the individually demeaned data `yxStar` and the 'between estimator' is a cross-sectional OLS on the individual means `yxbar`.\n",
    "\n",
    "### A Remark on the Code\n",
    "\n",
    "- `OlsNWFn(y,x,m=0)` is a function for doing OLS. Setting `m>=1` gives Newey-West standard errors. With `m=0` (the default) we instead get White's standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mPoint estimates:\u001b[22m\u001b[39m\n",
      "                Pooled        FE   Between\n",
      "exper/100        7.837     4.108    10.641\n",
      "exper^2/100     -0.201    -0.041    -0.317\n",
      "tenure/100       1.206     1.391     1.247\n",
      "tenure^2/100    -0.024    -0.090    -0.016\n",
      "south           -0.196    -0.016    -0.201\n",
      "union            0.110     0.064     0.121\n",
      "\n",
      "\u001b[34m\u001b[1mt-stats:\u001b[22m\u001b[39m\n",
      "                Pooled        FE   Between\n",
      "exper/100        8.954     5.917     4.573\n",
      "exper^2/100     -5.264    -1.466    -3.054\n",
      "tenure/100       2.346     3.975     0.883\n",
      "tenure^2/100    -0.828    -4.136    -0.198\n",
      "south          -13.247    -0.367    -6.519\n",
      "union            6.928     4.181     3.102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(b,res,yhat,Covb,R2,) = OlsNWFn(yx[:,1],yx[:,2:end])            #pooled OLS\n",
    "xutLS = hcat(b,b./sqrt.(diag(Covb)))\n",
    "xutLS = xutLS[2:end,:]                                          #drop the intercept from printing\n",
    "\n",
    "\n",
    "(b,res,yhat,Covb,R2,) = OlsNWFn(yxStar[:,1],yxStar[:,3:end])    #fixed effect, skip the constant\n",
    "xutFE = hcat(b,b./sqrt.(diag(Covb))*sqrt(NT-N-2)/sqrt(NT-2))\n",
    "s2_e  = sum(res.^2)/(NT-N-(K-1))              #needed for GLS (see below)\n",
    "\n",
    "\n",
    "(b,res,yhat,Covb,R2,) = OlsNWFn(yxbar[:,1],yxbar[:,2:end])      #between estimator\n",
    "xutB = hcat(b,b./sqrt.(diag(Covb)))\n",
    "xutB = xutB[2:end,:]                                            #skip the intercept\n",
    "s2_u = max(0,sum(res.^2)/(N-K) - s2_e/T)      #needed for GLS\n",
    "\n",
    "\n",
    "printblue(\"Point estimates:\")\n",
    "printmat([xutLS[:,1] xutFE[:,1] xutB[:,1]],colNames=[\"Pooled\",\"FE\",\"Between\"],rowNames=xNames)\n",
    "\n",
    "printblue(\"t-stats:\")\n",
    "printmat([xutLS[:,2] xutFE[:,2] xutB[:,2]],colNames=[\"Pooled\",\"FE\",\"Between\"],rowNames=xNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Difference Model\n",
    "\n",
    "To estimate the first-difference model, we first need to calculate the differences (over two time periods) for the *same individual*.\n",
    "\n",
    "### A Remark on the Code\n",
    "\n",
    "- In the cell below, we call on the function `lagFn` which lags the data once (as a default). For the first time period, the result is a NaN (as there are no earlier values). \n",
    "- After the loop we locate and delete all rows that include some NaNs. This means that we will have only $T-1$ data points for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of yxStarΔ: (2864, 8)\n"
     ]
    }
   ],
   "source": [
    "yxStarΔ = fill(NaN,size(yx))\n",
    "for i = 1:N                          #individual first-differencing, loop over individuals\n",
    "    #local vv_i                      #only in script\n",
    "    vv_i            = id .== id_uniq[i]   #rows in yx which refer to individual i\n",
    "    yxStarΔ[vv_i,:] = yx[vv_i,:] - lagFn(yx[vv_i,:])   #yx[t] -yx[t-1]\n",
    "end\n",
    "\n",
    "yxStarΔ = excise(yxStarΔ)          #cut out rows with NaNs\n",
    "yxStarΔ[:,2] .= 1                  #put a (non-zero) constant back\n",
    "\n",
    "println(\"size of yxStarΔ: \",size(yxStarΔ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m1-st difference estimation:\u001b[22m\u001b[39m\n",
      "                  Coef       Std\n",
      "exper/100        3.548     2.277\n",
      "exper^2/100     -0.045    -0.933\n",
      "tenure/100       1.293     2.527\n",
      "tenure^2/100    -0.083    -2.329\n",
      "south           -0.024    -0.395\n",
      "union            0.044     3.115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(b,res,yhat,Covb,R2,) = OlsNWFn(yxStarΔ[:,1],yxStarΔ[:,2:end])\n",
    "xutΔ = hcat(b,b./sqrt.(diag(Covb)))\n",
    "xutΔ = xutΔ[2:end,:]\n",
    "\n",
    "printblue(\"1-st difference estimation:\")\n",
    "printmat(xutΔ,colNames=[\"Coef\",\"Std\"],rowNames=xNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLS of Random Effects Model (extra)\n",
    "\n",
    "GLS is similar to the FE estimator discussed above, except that it is based on a 'quasi-demeaning' $y_{it} - \\vartheta\\bar{y_{it}}$ and similarly for $x_{it}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ϑ in GLS:      0.774          \n",
      "\n",
      "\u001b[34m\u001b[1mGLS:\u001b[22m\u001b[39m\n",
      "                  Coef       Std\n",
      "exper/100        4.570     7.111\n",
      "exper^2/100     -0.063    -2.387\n",
      "tenure/100       1.380     4.032\n",
      "tenure^2/100    -0.074    -3.575\n",
      "south           -0.132    -5.255\n",
      "union            0.075     5.611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ϑ = 1 - sqrt(s2_e)/sqrt(T*s2_u+s2_e)                       #GLS\n",
    "printlnPs(\"ϑ in GLS: \",ϑ,\"\\n\")\n",
    "\n",
    "yxStar_ϑ = fill(NaN,size(yx))\n",
    "for i = 1:N\n",
    "    #local vv_i              #local/global is needed in script\n",
    "    vv_i             = id .== id_uniq[i]\n",
    "    yxStar_ϑ[vv_i,:] = yx[vv_i,:] .- ϑ*yxbar[i:i,:]\n",
    "end\n",
    "\n",
    "(b,res,yhat,Covb,R2,) = OlsNWFn(yxStar_ϑ[:,1],yxStar_ϑ[:,2:end])\n",
    "xutGLS = hcat(b,b./sqrt.(diag(Covb)))\n",
    "xutGLS = xutGLS[2:end,:]\n",
    "\n",
    "printblue(\"GLS:\")\n",
    "printmat(xutGLS,colNames=[\"Coef\",\"Std\"],rowNames=xNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
